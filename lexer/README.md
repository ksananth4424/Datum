# Lexical Analysis

## Introduction

Lexical analysis is the process of converting a string of characters into a sequence of tokens. A token is a string with an assigned and thus identified meaning. The sequence of tokens is called a token stream. The token stream is used as input for the parser.

It can recognise all the keywords and operators mentioned in our Language whitepaper

## Testing

Go to the lexer folder and run the following

    $ make

    $$ make test

This should run the test cases and report their results

## References

ANSI C Lexer